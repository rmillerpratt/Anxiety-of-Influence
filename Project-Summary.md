# ANXIETY OF INFLUENCE
### Reception of the Fantastic in 19th-Century Spain

## IN THE BEGINNING

My objective with this project was to address the contentious issue of whether or not Spanish authors in the 19th century, had access to translations of non-Spanish language Fantastic texts. Specifically, I built a data set and used it to analyze frequency, location, and quantity of publications. The analysis was done through visualizations including maps and graphs. By using the raw data from the research of David Roas and Juan Jesús Payán Martín, on Spanish language translations of Fantastic literature in the 19th century, I created the data set that was used for this project.

## AND ON THE FIRST DAY

Increasing digitization and metadata development makes possible today a more accurate diagnosis of the patterns of translation that determined the horizon of expectation of Supernatural Fantastic texts in Spanish-speaking countries. My objective with this project was to address the contentious issue of whether or not authors in 19th-century Spain, had access to translations of non-Spanish language Fantastic texts. To do this, I built a data set compiled from the preliminary findings by two scholars of the Spanish Fantastic (David Roas and Juan Jesús Payán Martín). It had been my intention to extend this preliminary data set to reflect additional data that I planned to retrieve through API queries from digital catalogs at Hathi Trust, OCLC, and Biblioteca Nacional de España. Unfortunately, the initial data set required an unanticipated (tremendous) amount of time to gather, build, and clean and I did not have enough time to acquire the additional data from the APIs noted above. These data will be added during the next stages of this project.

For this first stage of the project I located translation publication information from several publications by the two scholars noted above, D. Roas and J.J. Payán Martín. I reviewed their raw data, which included numerous annotations and extraneous detail, to determine whether or not they were relevant. I established the following list as essential elements and eliminated the rest: Author Last Name, Author First Name, Publication Title (in Spanish), Publication Year (Spanish translation), Publication City (Spanish translation), Publisher Name (Spanish translation), Original Publication Year, Original Publication Country, Original Publication City, Title of Publication (in original language).

Since this information was taken from several books, I would first need to scan the pages where the information was located into pdf documents and  use Adobe Acrobat’s OCR (Optical Character Recognition) function to create a text file which I then saved as a csv file. I imported the csv file into a text editor (Atom) and then reviewed it for mistakes and made corrections based on the original pdf documents. I then imported the .csv file into OpenRefine where I created a tabular version of the data. In OpenRefine I was able to create column headings for the data I wanted to use for my analysis: Author Last Name, Author First Name, Publication Title (in Spanish), Publication Year (Spanish translation), Original Publication Year, Publication City (Spanish translation), Publisher Name, Original Publication Country, Original Publication City, Title of Publication (in original language). I then used the text facet, edit-transform, and transpose functions to standardize the data set in large batches, something was would have taken ages in Atom. In summary, to prepare my data set for exploratory analysis I did the following:
* Acquired data via OCR using Adobe Acrobat Reader
* Text Wrangling with Atom
* Data Cleaning with OpenRefine

## AND THEN THERE WAS A DATA SET

Now that my data set was cleaned up, I was finally in a position to begin analyzing the data. I had decided to analyze frequency, location, and quantity of the publication of translations of Fantastic literature in Spain in the 19th-century. To do this I used a Juypter Notebook and Python with a number of it’s libraries: geopy, nominatim, numpy, matplotlib.pyplot, and pandas. I first imported my csv file into a Jupyter Notebook to see if I could see if any patterns emerged. I used several scripts to create tables and lists from my data set. The first thing that became apparent, there were two main hubs for translation publication, Madrid and Barcelona, which was not a great surprise as these are still two of the largest publication hubs in Spain. Second, I wanted to see from which countries the Fantastic works originated. I was surprised that the majority of the translated works originated in France - 226, followed by the UK - 91, and then the US - 76. Now that I had a better understanding of my data, I needed to geocode my data so that I could move on to the next stage of my analysis, bringing my data set into Carto. I used a script in Python and the geopy, nominatim, and pandas libraries to geocode my data set. I was now ready to import my geocoded file into Carto and conduct some spatial analyses.

## AND ON THE EIGHTH DAY

As I noted at the beginning of this write up, this is only the first stage of my work on the translation of foreign Fantastic works of literature in 19th-century Spain. The small (less than 500 works) data set that I built contains just a small fraction of the works that I believe were translated. I had initially wanted to use several APIs to pull data on translations from the Hathi Trust, OCLC, and Biblioteca Nacional de España. Unfortunately, after I began cleaning my data set, I knew that there would not be enough time to acquire this new data and clean it during this semester. The most important lesson learned, never underestimate the amount of time needed just to prepare your data set. There were so many new questions that arose from this exploratory analysis. Who were the translators? Where were they from? Since national borders have changed since the 19th-century, perhaps it would make sense to look at the original language the work was created in, rather than the origin “country”. I do hope that eventually I will be able to present this data as an interactive website that other scholars in the field can access and add to in support of their research.
